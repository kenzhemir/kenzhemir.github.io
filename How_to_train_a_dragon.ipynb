{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How_to_train_a_dragon.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/kenzhemir/kenzhemir.github.io/blob/master/How_to_train_a_dragon.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "pkdU7kAjfWhE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Why Convolutional Neural Networks? \n",
        "\n",
        "AlphaGO\n",
        "\n",
        "![alt text](https://cdn57.androidauthority.net/wp-content/uploads/2016/03/FACEBOOK-RESULTS-CARD-DAY-5-01-840x440.jpg)\n",
        "\n",
        "OpenAI and Dota 2\n",
        "\n",
        "![alt text](https://i2.wp.com/anith.com/wp-content/uploads/2017/08/elon-musks-self-taught-ai-bot-destroyed-an-esports-pro-in-dota-2.jpg?fit=1200%2C630&ssl=1)"
      ]
    },
    {
      "metadata": {
        "id": "Qy7BV_Q6MGGH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# What is classification?\n",
        "Basic task in Computer Vision\n",
        "\n",
        "## Training: \n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*oB3S5yHHhvougJkPXuc8og.gif)\n",
        "\n",
        "## Testing: \n",
        "![alt text](https://sourcedexter.com/wp-content/uploads/2017/05/tensorflow-1.gif)"
      ]
    },
    {
      "metadata": {
        "id": "inybqIrxQ4py",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Why it is difficult?!\n",
        "\n",
        "1.   Semantic Gap - Did machines see the same way we do? Nope\n",
        "2.   Illumination\n",
        "3.   View point\n",
        "4.   Deformation\n",
        "5.   Occlusion\n",
        "6.   Background Clutter\n",
        "7.   Intraclass variation\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "oGJfCtGDSE9X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How to approach the Problem???  \n",
        "\n",
        "Just collect the data and hope algorithm will figure it out (aka Data-Driven Approach): \n",
        "\n",
        "1. Collect a dataset of images and labels (Easier sad than done)\n",
        "2. Use Machine Learning to train a classifier\n",
        "3. Evaluate the classifier on new images\n",
        "\n",
        "![alt text](https://imgs.xkcd.com/comics/machine_learning.png)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KtShbyTfTKX5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classifiers \n",
        "\n",
        "1. Nearest Neighbor (Remeber existing data and find the closest match at inference) \\\\\n",
        "Too slow (espessially if the dataset is big and complex)\n",
        "2. Linear Classifier f(x,W) = Wx\n"
      ]
    },
    {
      "metadata": {
        "id": "v8cr0SBxUQgU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Now how we can implement that?\n",
        "#### What you'll learn\n",
        "\n",
        "1. What is a neural network and how to train it\n",
        "2. How to build a basic 1-layer FC neural network using PyTorch\n",
        "3. How to add more layers\n",
        "4. How to pick hyperparams for your model\n",
        "5. How to build convolutional networks and train them\n",
        "\n",
        "How about overfitting, dropout, learning rate decay? \n"
      ]
    },
    {
      "metadata": {
        "id": "QByvanOV1Lam",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install Pytorch to Colab VM \n",
        "Pytorch is an awesome Deep Learning Framework from Facebook [link text](http://pytorch.org) \\\\\n",
        "Colab - Google actually gives you a free GPU for a limited time (12 hours) and you can run your code in Jupyter Notebook in the brower ))) \\\\\n",
        "Isn't that GREAAAAT ?\n"
      ]
    },
    {
      "metadata": {
        "id": "SkLIEF161GKi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKkkGQps1TYm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import all necessary packages"
      ]
    },
    {
      "metadata": {
        "id": "4dUrEmvO1YUn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import PIL.Image as image\n",
        "import torchvision.models as model\n",
        "from torch.autograd import Variable as v\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s4-Ru4Q91hF8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "For this experiments we will be using MNIST dataset"
      ]
    },
    {
      "metadata": {
        "id": "C-qJ7liy1qJQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "root = './data'\n",
        "download = True\n",
        "batch_size = 64\n",
        "cuda = torch.cuda.is_available()\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
        "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(root, train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(root, train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size = batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U3G9K96F3nvQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Look at your data"
      ]
    },
    {
      "metadata": {
        "id": "yrdtxfcC3qNZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "df491995-b2ad-4798-e69d-1192647df9a7"
      },
      "cell_type": "code",
      "source": [
        "def imshow(inp, name, title=None):\n",
        "    import pylab\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    #inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = inp.squeeze().numpy()\n",
        "    mean = np.array([0.1307])\n",
        "    std = np.array([0.3081])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp,  cmap=pylab.gray())\n",
        "    result = image.fromarray((inp * 255).astype(np.uint8))\n",
        "  #  result.save(name)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    \n",
        "for batch_idx, (data, target) in enumerate(train_loader):\n",
        "  sample = data[20] # change number to any id in the batch \n",
        "  imshow(sample, 'sample')\n",
        "  break\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S-At5xLqB2yu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/d5222c6e3d15770a.png)"
      ]
    },
    {
      "metadata": {
        "id": "4yhDUAoV5Fpz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create a model for training\n",
        "New model class is defined as a new nn.Module"
      ]
    },
    {
      "metadata": {
        "id": "yBGBK5HM9PzK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## FC\n",
        "\n",
        "Let's start with a simple Fully Connected Network"
      ]
    },
    {
      "metadata": {
        "id": "bBA_KzMUAzTK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Simple_FC(nn.Module):\n",
        "    def __init__(self, input_size=784, num_classes=10):\n",
        "        super(Simple_FC, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        out = self.fc1(x) # weighted sum of input and network weights -> Wx+b, b - bias\n",
        "        return out # return logits - activations before softmax layer "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dk1JDsOL8lAT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Softmax \n",
        "\n",
        "transfers scores (logits) into class probabilities. \\\\\n",
        "Entries are normalized -> sum up to 1\n",
        "\n",
        "![alt text](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/604a9797da2a48d7.png)"
      ]
    },
    {
      "metadata": {
        "id": "qyQdyuzP9Nd6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Complex_FC(nn.Module):\n",
        "    def __init__(self, input_size=784, hidden_size=500, num_classes=10):\n",
        "        super(Complex_FC, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6alIPVw3uZe0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Deep_FC(nn.Module):\n",
        "    def __init__(self, input_size=784, num_classes=10):\n",
        "        super(Deep_FC, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 200) \n",
        "        self.activation = nn.Sigmoid()\n",
        "        self.fc2 = nn.Linear(200, 100)  \n",
        "        self.fc3 = nn.Linear(100, 60) \n",
        "        self.fc4 = nn.Linear(60, 30)  \n",
        "        self.fc5 = nn.Linear(30, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc5(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "buI_vFTP9eoC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN\n",
        "Now let's see how we get even more from the network with a better architecture (CNN) "
      ]
    },
    {
      "metadata": {
        "id": "iu1DYw-n5N6f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*20, 50) # Fully Connected Layers \n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "        self.bn1 = nn.BatchNorm2d(10)\n",
        "        self.bn2 = nn.BatchNorm2d(20)\n",
        "        self.bn3 = nn.BatchNorm1d(50)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(F.max_pool2d(self.bn1(self.conv1(x)), 2))\n",
        "        x = F.relu(F.max_pool2d(self.bn2(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 16*20)\n",
        "        x = F.relu(self.bn3(self.fc1(x)))\n",
        "        x = F.dropout(x, p=0.25)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o2lqVn6SwRJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " def adjust_learning_rate(lr, optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 after 150 and 225 epochs\"\"\"\n",
        "    lr = lr * (0.1 ** (epoch // 8)) # 6\n",
        "\n",
        "    print ('Learning rate: ' + str(lr))\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "htjxOKrNLwcy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://i.stack.imgur.com/FjvuN.gif)"
      ]
    },
    {
      "metadata": {
        "id": "0JqcoNmh95Uo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pick model for testing"
      ]
    },
    {
      "metadata": {
        "id": "rbBOhJv46Jfy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Simple_FC()\n",
        "#model = Complex_FC()\n",
        "#model = Deep_FC()\n",
        "#model = CNN()\n",
        "if cuda:\n",
        "    model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q7k6XE5J6M9v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define a Loss Function(Criterion) and an Optimizer\n"
      ]
    },
    {
      "metadata": {
        "id": "qkFyyXAK6MfL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr = 0.001 # 0.01  \n",
        "momentum = 0.9\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_BeUR3h9Hhu0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How to choose your learning rate ???\n",
        "\n",
        "Hyperparameter - not-leranable parameter and picked manually in the begging of training \\\\\n",
        "Try and see what works best \\\\\n",
        "\n",
        "Check behavious: \n",
        "1. Simple_FC with lr = 0.01, 0.001, 0.0001\n",
        "2. Complex_FC with lr = 0.01, 0.001, 0.0001\n",
        "3. CNN with lr = 0.1, 0.01 \n",
        "\n",
        "![alt text](http://cs231n.github.io/assets/nn3/learningrates.jpeg)"
      ]
    },
    {
      "metadata": {
        "id": "bavgM7btH1pY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Momentum ??? \n",
        " - running average of previous updates! Small oscillations \n",
        " \n",
        " `V = momentum*V + (1-momentum)*gradient_of_parameters`\n",
        " \n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*5-GPmnonHVQiIj2EPG3Fgw.png)\n",
        "\n",
        "Without Momentum -> \n",
        "\n",
        "```\n",
        "update = learning_rate * gradient_of_parameters\n",
        "parameters = parameters - update\n",
        "\n",
        "```\n",
        "\n",
        "![alt text](https://qph.fs.quoracdn.net/main-qimg-7adad11c6ee947a96e917e2a8205392d)\n",
        "\n",
        "With Momentum \n",
        "```\n",
        "V = momentum*V + (1-momentum)*gradient_of_parameters\n",
        "W = W - learning_rate * V\n",
        "\n",
        "```\n",
        "\n",
        "![alt text](https://deeplearning4j.org/img/updater_2.png)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "zVXG7IlxCzoW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loss? How cross-entropy loss is calculated? \n",
        "Loss is a way to quantifying what it means to have a “good” classifier\n",
        "![alt text](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/1d8fc59e6a674f1c.png)\n",
        "\n",
        "\n",
        "**Note!!!** In Pytorch obtaining log-probabilities in a neural network is easily achieved by adding a  `LogSoftmax`  layer in the last layer of your network and use `NLLLoss` (The negative log likelihood loss)\n",
        "You may use `CrossEntropyLoss` instead, if you prefer not to add an extra layer."
      ]
    },
    {
      "metadata": {
        "id": "s6d5LVkXDXaH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How is essentially optimization works? (in the Perfect World)\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*bl1EuPH_XEGvMcMW6ZloNg.jpeg)\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "S0w-4uFa7HU8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_interval = 100\n",
        "def train(epoch):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "       \n",
        "        if cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward() # calculate gradients\n",
        "        optimizer.step() # update network parameters\n",
        "            \n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.00f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
        "            \n",
        "            # Compute accuracy\n",
        "            _, argmax = torch.max(output, 1)\n",
        "            accuracy = (target == argmax.squeeze()).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_E6vI1aPDwk6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## But real life is not perfect. So your real function will probably look like that. Still quit good \n",
        "In this picture, loss is represented as a function of 2 parameters. In reality, there are many more\n",
        "![alt text](https://cdn-images-1.medium.com/max/1200/1*msObu3xbQzSnKvtCW2z6YQ.png)"
      ]
    },
    {
      "metadata": {
        "id": "l1QqrOf07CdK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Specify the training Procedure"
      ]
    },
    {
      "metadata": {
        "id": "ZLYPUPqB8qdm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Check the model accuracy "
      ]
    },
    {
      "metadata": {
        "id": "kxsnSEvA8vsJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += criterion(output, target).data[0]\n",
        "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "\n",
        "    test_loss = test_loss\n",
        "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NYrKRLW37k4t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Let's Finally Train your Created Model"
      ]
    },
    {
      "metadata": {
        "id": "5rcTY3Jy7aX5",
        "colab_type": "code",
        "colab": {},
        "outputId": "0e2f7a2b-dc45-48d0-8171-38731fc27749"
      },
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "for epoch in range(1, epochs + 1):\n",
        "   # adjust_learning_rate(lr, optimizer, epoch)\n",
        "    train(epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s4TsRr9A86KB",
        "colab_type": "code",
        "colab": {},
        "outputId": "586a511d-5b42-446f-9bc1-ba9fa30b4a13"
      },
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fgyjvwfdNleh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# What to do next \n",
        "\n",
        "\n",
        "1.   More complex Datasets (CIFAR, ImageNet). You even can make your own\n",
        "2.   Transfer Learning from Pre-trained models. \n",
        "3.   How my filters look like ???? Feature Visualization\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wZRpKeMlVuru",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Are not done with AI? Not yet. What are the limits????\n",
        "\n",
        "1.   No system is secure. Classifier can easily be tricked? How Adversarial examples are?\n",
        "2.   To train a classifier we need data (much that humans require). What if we cannot find more? Or we are too lazy to annotate? \n",
        "3.   Your algorithm is as good as your data. What if your data is biased? (**Spoiler Alert!!!** Your data is biased)"
      ]
    },
    {
      "metadata": {
        "id": "7UP9Jzo_znRz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Advesarial Examples\n",
        "\n",
        "Images appearing similiar to humans, but misclassified by the neural networks. \n",
        "Adversarial Examples causes a state-of-the-art neural network to mis-classify any input image to whatever class we choose\n",
        "\n",
        "**Example: **\n",
        "\n",
        "![alt text](http://cleverhans.io/assets/adversarial-example.png)\n",
        "\n",
        "\n",
        "## How we can generate Advesarial Examples\n",
        "![alt text](http://dev.wode.ai/repo/TensorFlow-Tutorials-HvassLabs/images/11_adversarial_examples_flowchart.svg)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GPtRyBybBRkk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Advesarial Glasses\n",
        "![alt text](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/7f57e9939560562727344c1c987416285ef76cda/9-Figure4-1.png)\n",
        "\n",
        "Figure 4: Examples of successful impersonation and dodging attacks. Fig. (a) shows SA (top) and SB (bottom) dodging against DNNB . Fig. (b)–(d) show impersonations. Impersonators carrying out the attack are shown in the top row and corresponding impersonation targets in the bottom row. Fig. (b) shows SA impersonating Milla Jovovich (by Georges Biard; source: https://goo.gl/GlsWlC); (c) SB impersonating SC ; and (d) SC impersonating Carson Daly (by Anthony Quintano; source: https://goo.gl/VfnDct)"
      ]
    },
    {
      "metadata": {
        "id": "GFo5dQ4x_3Wq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How to defend against Advesarial Examples? \n",
        "\n",
        "1. Include into training \n",
        "2. Train a separate network to detect an Advesarial Examples"
      ]
    }
  ]
}